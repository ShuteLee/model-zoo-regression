//===-*- Groovy -*-===
import java.util.Random
import java.text.SimpleDateFormat
import java.util.Date

def sync_repository_github(name) {
    def url = "https://github.com/sophgo/${name}.git"
    println("sync the latest codes")
    println("repository name: " + name + ", url: " + url)
    sync_repostory(name, url)
}

def sync_repository_gerrit(name) {
    def url = "https://${GERRIT_AC_USR}:${GERRIT_AC_PSW}@gerrit-ai.sophgo.vip:8443/a/${name}"
    println("sync the latest codes")
    println("repository name: " + name + ", url: " + url)
    sync_repostory(name, url)
}

def sync_repostory(name, url) {
    sh """#!/bin/bash
        set -e
        if [ -d "${name}" ]; then
            pushd ${name}
            git pull && git submodule update
            popd
        else
            git clone ${url}
        fi
    """
}

def query_latestes_build_sucess(case_name) {
    getDatabaseConnection(type: 'GLOBAL') {
        def results = sql(sql: "SELECT commit_sha FROM build_table WHERE case_name=\"${case_name}\" AND build_status=0 ORDER BY build_id DESC LIMIT 1;")
        println("query results, latestes_build_sucess: ${results}")
        return results
    }
}

def print_database() {
    getDatabaseConnection(type: 'GLOBAL') {
        def results = sql(sql: "SELECT * FROM build_table;")
        println("build_table: ${results}")
    }
    getDatabaseConnection(type: 'GLOBAL') {
        def results = sql(sql: "SELECT * FROM runtime_table;")
        println("runtime_table: ${results}")
    }
}

// def insert_dummy_data() {
//     def rand = new Random()
//     def case_name_l = ['ppocr', 'mobilenet', 'resnet', 'resNext', 'yolo']
//     def target_l = ['BM1684', 'BM1684X']
//     def toolchain_l = ['nntoolchain', 'tpu-mlir']
//     for (int i=0; i<10; i++) {
//         def 
//         getDatabaseConnection(type: 'GLOBAL') {
//             def results = sql(sql: "INSERT INTO build_table (pipeline_id, commit_sha, case_name, build_status, toolchain, target, build_time, runtime_id, date) VALUES ();")
//         }
//     }
// }

def insert_build_data(data) {
    getDatabaseConnection(type: 'GLOBAL') {
        return sql(sql: "INSERT INTO build_table (pipeline_id, commit_sha, case_name, build_status, toolchain, target, build_time, runtime_id, date) VALUES (${data['pipeline_id']}, \"${data['commit_sha']}\", \"${data['case_name']}\", ${data['build_status']}, \"${data['toolchain']}\", \"${data['target']}\", ${data['build_time']}, ${data['runtime_id']}, \"${data['date']}\"); SELECT LAST_INSERT_ID() FROM build_table")
        // return sql(sql: "SELECT LAST_INSERT_ID() FROM `build_table`")
    }
}

def update_runtime_id_in_build(build_id, runtime_id) {
    getDatabaseConnection(type: 'GLOBAL') {
        sql(sql: "UPDATE build_table SET runtime_id=${runtime_id} WHERE id=${build_id};")
    }
}

def insert_runtime_data(data) {
    getDatabaseConnection(type: 'GLOBAL') {
        return sql(sql: "INSERT INTO runtime_table (pipeline_id, build_id, runtime_status, target, name, dyn, opt, prec, shape, gops, time, mac_utiliz, ddr_utiliz, cpu_usage, device_id, driver_version, date) VALUES (${data['pipeline_id']}, ${data['build_id']}, ${data['runtime_status']}, \"${data['target']}\", \"${data['name']}\", ${data['dyn']}, ${data['opt']}, ${data['prec']}, \"${data['shape']}\", ${data['gops']}, ${data['time']}, ${data['mac_utiliz']}, ${data['ddr_utiliz']}, ${data['cpu_usage']}, ${data['device_id']}, \"${data['driver_version']}\", \"${data['date']}\"); SELECT LAST_INSERT_ID() FROM runtime_table")
        // return sql(sql: "SELECT LAST_INSERT_ID() FROM `runtime_table`")
    }
}

def gen_dummy_build_data(pipeline_id, commit_sha, date) {
    def dummy_toolchains = ['nntoolchain', 'tpu-mlir']
    def dummy_targets = ['BM1684', 'BM1684X']
    def dummy_names = ['yolo', 'mobile_net', 'maskrcnn', 'ppocr', 'resnet']
    def rand = new Random()
    return ['pipeline_id':pipeline_id, 'commit_sha':commit_sha, 'case_name':dummy_names[rand.nextInt(5)], 'build_status':rand.nextInt(2), 'toolchain':dummy_toolchains[rand.nextInt(2)], 'target':dummy_targets[rand.nextInt(2)], 'build_time':rand.nextDouble()*10, 'runtime_id':-1, 'date':date]
}

def gen_dummy_runtime_data(pipeline_id, date) {
    def dummy_toolchains = ['nntoolchain', 'tpu-mlir']
    def dummy_targets = ['BM1684', 'BM1684X']
    def dummy_names = ['yolo', 'mobile_net', 'maskrcnn', 'ppocr', 'resnet']
    def dummy_shapes = ['1x3x224x224', '4x3x64x128', '1x3x640x640', '1x3x64x128', '1x3x320x640']
    def rand = new Random()
    return ['pipeline_id':pipeline_id, 'build_id':-1, 'runtime_status':rand.nextInt(2), 'target':dummy_targets[rand.nextInt(2)], 'name':dummy_names[rand.nextInt(5)], 'dyn':rand.nextInt(2), 'opt':rand.nextInt(3), 'prec':rand.nextDouble(), 'shape':dummy_shapes[rand.nextInt(5)], 'gops':rand.nextDouble()*10, 'time':rand.nextDouble()*100, 'mac_utiliz':rand.nextDouble(), 'ddr_utiliz':rand.nextDouble(), 'cpu_usage':rand.nextDouble(), 'device_id':rand.nextInt(10), 'driver_version':'20220402_dailybuild_a3dfsdg', 'date':date]
}

pipeline {
    agent {
        label 'linux-sc5-sc7'
    }
    environment {
        GIT_REPOSTORY_PATH = "/git-repository"
        GERRIT_AC = credentials('gerrit-ac')
        GIT_SSL_NO_VERIFY = 1
        DATA_SERVER = "http://172.28.9.198/webdav/dataset"
        FTP_SERVER = "ftp://AI:SophgoRelease2022@172.28.141.89"
        SWAP_SERVER = "http://172.28.142.120/webdav/swap"
        OUTPUT_TMP = "/tmp/dummy.github.output.txt"
    }
    stages {
        stage('Information') {
            steps {
                println("----hello world----")
                sh """#!/bin/bash
                    set -e
                    apt-get update
                    apt-get install git -y
                    apt-get install git-lfs -y
                    apt-get install tree -y
                    git config --unset core.hooksPath
                    git lfs install --force
                """
            }
        }
        stage('CodeSync') {
            steps {
                dir("$WORKSPACE") {
                    script {
                        if (params.TOOLCHAIN == "nntoolchain") {
                            sync_repository_gerrit("libsophon")
                            sync_repository_gerrit("bm_prebuilt_toolchains")
                            sync_repository_gerrit("nntoolchain")
                        } else if (params.TOOLCHAIN == "tpu-mlir") {
                            sync_repository_gerrit("tpu-mlir")
                        }
                        sync_repository_github("model-zoo")
                        sync_repostory("blame-regression", "https://github.com/QinyuZHAO0/blame-regression.git")
                        def lss = sh(script: "tree -L 2", returnStdout: true)
                        println(lss)
                    }
                }
                dir("${WORKSPACE}/blame-regression/test") {
                    sh """#!/bin/bash
                        set -e
                        pip3 install -r requirements.txt
                    """
                }
            }
        }
        stage('Process') {
            steps {
                dir("$WORKSPACE") {
                    script {
                        println("--- process start ---")
                        def rand = new Random()
                        println("--xx--")
                        def pipeline_id = "${BUILD_ID}"
                        println("--xxx--")
                        def commit_n_sha = sh(script: '''git log  --pretty=oneline -n 30 --pretty=format:\"%h\"''', returnStdout: true)
                        def commit_n = commit_n_sha.split("\n")
                        println(commit_n)
                        for (int i=0; i<10; i++) {
                            println("============================================= $i =====================================")
                            def cmt_id = commit_n[rand.nextInt(30)]
                            def date = new Date().format("yyyy-MM-dd", TimeZone.getTimeZone('UTC'))
                            def startTime = new Date().getTime()
                            def build_res = gen_dummy_build_data(pipeline_id, cmt_id, date)
                            println("build_res: ${build_res}")
                            def endTime = new Date().getTime()
                            def duringTime = endTime - startTime
                            println("during time: ${duringTime}")
                            if (build_res['build_status'] == 0) {
                                println("--------catch first sucess : ${build_res}----------")
                                def build_id = insert_build_data(build_res)
                                def runtime_res = gen_dummy_runtime_data(pipeline_id, date)
                                println("------runtime : ${runtime_res}--------")
                                def runtime_id = insert_runtime_data(runtime_res)
                                update_runtime_id_in_build(build_id, runtime_id)
                            } else {
                                println("--------catch failer : ${build_res}----------")
                                def build_id = insert_build_data(build_res)
                            }
                            print_database()
                        }
                    }
                }
            }
        }
    }
}